# ğŸŒ Wikipedia Scraper 



## ğŸ§­ Project Overview

This project is part of my data science learning journey â€” focused on **data collection and web scraping**.  
The goal was to build a **complete scraper** that:
1. Retrieves political leadersâ€™ data from an API,  
2. Scrapes their Wikipedia introduction paragraphs, and  
3. Saves everything as structured **JSON** or **CSV** files.

Scraping and data retrieval are common first steps in any data project.

---

## ğŸ¯ Mission Objectives

 âœ… Work inside a **self-contained environment** (`venv`)\
 âœ… Retrieve data from an external **REST API**\
 âœ… **Scrape** data from HTML pages using BeautifulSoup\
 âœ… Handle cookies, exceptions, and files properly\
 âœ… Save and reuse data in **JSON** and **CSV** formats\
 âœ… Build both **functional** and **object-oriented** versions

---

## ğŸ§  Learning Outcomes

This project helped me practice and strengthen the following Python skills:

| Area | Description |
|-------|--------------|
| ğŸ§° **Python Libraries** | `os`, `requests`, `json`, `csv`, `beautifulsoup4` |
| ğŸŒ **Requests & Sessions** | Calling APIs, reusing sessions for efficiency |
| ğŸª **Cookies Handling** | Refreshing expired cookies  |
| ğŸ“œ **BeautifulSoup** | Extracting first paragraphs from Wikipedia pages |
| âš™ï¸ **Exception Handling** | Managing connection errors, invalid data, retries |
| ğŸ’¾ **File Handling** | Writing output to `leaders.json` and `leaders.csv` |
| ğŸ§± **OOP Concepts** | Refactoring procedural code into class-based structure |

---

## ğŸš€ The Mission

The main task was to collect and combine data from two sources:
- The **Country Leaders API** ğŸ‘‰ [https://country-leaders.onrender.com/docs](https://country-leaders.onrender.com/docs)  
- The leadersâ€™ **Wikipedia pages**

### Steps:
1. Fetch the list of countries from the API.  
2. Retrieve all political leaders for each country.  
3. Visit each leaderâ€™s Wikipedia page and scrape the first `<p>` paragraph.  
4. Save all results in `leaders.json` or `leaders.csv`.

---

## ğŸ§© Project Structure

```
wikipedia-scraper/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ leaders_scraper.py            # Functional version (non-OOP)
â”‚ â”œâ”€â”€ leaders_scraper_oop.py        # OOP version (WikipediaScraper class)
â”‚ â””â”€â”€ pycache/                      # Compiled cache
â”‚
â”œâ”€â”€ wikipedia_scraper_env/          # Virtual environment folder
â”œâ”€â”€ main.py                         # Entry point (runs OOP scraper)
â”œâ”€â”€ leaders.json                    # Saved output (JSON)
â”œâ”€â”€ leaders.csv                     # Saved output (CSV)
â”œâ”€â”€ wikipedia_scraper.ipynb         # Jupyter notebook version
â””â”€â”€ README.md                       # Project documentation

```

---

## âš™ï¸ How to Run

1ï¸âƒ£ Clone the repository** to your local machine: 

2ï¸âƒ£ Activate the virtual environment (make sure wikipedia_scraper_env exists):

```
source wikipedia_scraper_env/bin/activate       # macOS/Linux
# OR
wikipedia_scraper_env\Scripts\activate          # Windows
```

3ï¸âƒ£ Run the program â€” execute main.py from the command line:
```
python3 main.py
```

4ï¸âƒ£ View the result


## ğŸ§± Code Versions
ğŸ“œ Functional Version (src/leaders_scraper.py)

A step-by-step implementation using functions like:
- get_first_paragraph()
-  get_leader()
-  save_json()
-  save_csv()

ğŸ§­ OOP Version (src/leaders_scraper_oop.py)

An improved, object-oriented version with cleaner structure:

1. Attributes:  
             root_url, cookie_url, countries_url, leader_url, leaders_data, cookie, session
   
2. Methods:
- refresh_cookie()
- get_countries()
- get_leaders(country)
- get_first_paragraph(wikipedia_url)
- save() and save_csv()

## â±ï¸ Timeline

This project took 3 days for completion.


## ğŸ§‘â€ğŸ’» Author

Astha Gudgilla\
ğŸŒ± This project was done as part of the AI Bootcamp at BeCode.org.\
ğŸ“« Connect with me on [LinkedIn](https://www.linkedin.com/in/asthagudgilla/).

